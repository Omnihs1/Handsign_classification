{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils.tgcn import ConvTemporalGraphical\n",
    "from utils.graph import Graph\n",
    "from torchinfo import summary\n",
    "\n",
    "class Model(nn.Module):\n",
    "    r\"\"\"Spatial temporal graph convolutional networks.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input data\n",
    "        num_class (int): Number of classes for the classification task\n",
    "        graph_args (dict): The arguments for building the graph\n",
    "        edge_importance_weighting (bool): If ``True``, adds a learnable\n",
    "            importance weighting to the edges of the graph\n",
    "        **kwargs (optional): Other parameters for graph convolution units\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in}, M_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "            :math:`M_{in}` is the number of instance in a frame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, num_class, graph_args,\n",
    "                 edge_importance_weighting, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # load graph\n",
    "        self.graph = Graph(**graph_args)\n",
    "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # build networks\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(self.A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        # fcn for prediction\n",
    "        self.fcn = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.size()\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        x = x.view(N * M, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = x.view(N * M, C, T, V)\n",
    "\n",
    "        # forwad\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        # global pooling\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = x.view(N, M, -1, 1, 1).mean(dim=1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extract_feature(self, x):\n",
    "\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.size()\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        x = x.view(N * M, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = x.view(N * M, C, T, V)\n",
    "\n",
    "        # forwad\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        _, c, t, v = x.size()\n",
    "        feature = x.view(N, M, c, t, v).permute(0, 2, 3, 4, 1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        output = x.view(N, M, -1, t, v).permute(0, 2, 3, 4, 1)\n",
    "\n",
    "        return output, feature\n",
    "\n",
    "class st_gcn(nn.Module):\n",
    "    r\"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input sequence data\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (tuple): Size of the temporal convolving kernel and graph convolving kernel\n",
    "        stride (int, optional): Stride of the temporal convolution. Default: 1\n",
    "        dropout (int, optional): Dropout rate of the final output. Default: 0\n",
    "        residual (bool, optional): If ``True``, applies a residual mechanism. Default: ``True``\n",
    "\n",
    "    Shape:\n",
    "        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)` format\n",
    "        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format\n",
    "        - Output[0]: Outpu graph sequence in :math:`(N, out_channels, T_{out}, V)` format\n",
    "        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V, V)` format\n",
    "\n",
    "        where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "            :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "            :math:`V` is the number of graph nodes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 dropout=0,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "\n",
    "        self.gcn = ConvTemporalGraphical(in_channels, out_channels,\n",
    "                                         kernel_size[1])\n",
    "\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                (kernel_size[0], 1),\n",
    "                (stride, 1),\n",
    "                padding,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(dropout, inplace=True),\n",
    "        )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=(stride, 1)),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "\n",
    "        res = self.residual(x)\n",
    "        x, A = self.gcn(x, A)\n",
    "        x = self.tcn(x) + res\n",
    "\n",
    "        return self.relu(x), A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
       "========================================================================================================================\n",
       "Model                                         [32, 3, 80, 18, 1]        [32, 20]                  --\n",
       "├─BatchNorm1d: 1-1                            [32, 54, 80]              [32, 54, 80]              108\n",
       "├─ModuleList: 1-2                             --                        --                        --\n",
       "│    └─st_gcn: 2-1                            [32, 3, 80, 18]           [32, 64, 80, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-1        [32, 3, 80, 18]           [32, 64, 80, 18]          256\n",
       "│    │    └─Sequential: 3-2                   [32, 64, 80, 18]          [32, 64, 80, 18]          37,184\n",
       "│    │    └─ReLU: 3-3                         [32, 64, 80, 18]          [32, 64, 80, 18]          --\n",
       "│    └─st_gcn: 2-2                            [32, 64, 80, 18]          [32, 64, 80, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-4        [32, 64, 80, 18]          [32, 64, 80, 18]          4,160\n",
       "│    │    └─Sequential: 3-5                   [32, 64, 80, 18]          [32, 64, 80, 18]          37,184\n",
       "│    │    └─ReLU: 3-6                         [32, 64, 80, 18]          [32, 64, 80, 18]          --\n",
       "│    └─st_gcn: 2-3                            [32, 64, 80, 18]          [32, 64, 80, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-7        [32, 64, 80, 18]          [32, 64, 80, 18]          4,160\n",
       "│    │    └─Sequential: 3-8                   [32, 64, 80, 18]          [32, 64, 80, 18]          37,184\n",
       "│    │    └─ReLU: 3-9                         [32, 64, 80, 18]          [32, 64, 80, 18]          --\n",
       "│    └─st_gcn: 2-4                            [32, 64, 80, 18]          [32, 64, 80, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-10       [32, 64, 80, 18]          [32, 64, 80, 18]          4,160\n",
       "│    │    └─Sequential: 3-11                  [32, 64, 80, 18]          [32, 64, 80, 18]          37,184\n",
       "│    │    └─ReLU: 3-12                        [32, 64, 80, 18]          [32, 64, 80, 18]          --\n",
       "│    └─st_gcn: 2-5                            [32, 64, 80, 18]          [32, 128, 40, 18]         --\n",
       "│    │    └─Sequential: 3-13                  [32, 64, 80, 18]          [32, 128, 40, 18]         8,576\n",
       "│    │    └─ConvTemporalGraphical: 3-14       [32, 64, 80, 18]          [32, 128, 80, 18]         8,320\n",
       "│    │    └─Sequential: 3-15                  [32, 128, 80, 18]         [32, 128, 40, 18]         148,096\n",
       "│    │    └─ReLU: 3-16                        [32, 128, 40, 18]         [32, 128, 40, 18]         --\n",
       "│    └─st_gcn: 2-6                            [32, 128, 40, 18]         [32, 128, 40, 18]         --\n",
       "│    │    └─ConvTemporalGraphical: 3-17       [32, 128, 40, 18]         [32, 128, 40, 18]         16,512\n",
       "│    │    └─Sequential: 3-18                  [32, 128, 40, 18]         [32, 128, 40, 18]         148,096\n",
       "│    │    └─ReLU: 3-19                        [32, 128, 40, 18]         [32, 128, 40, 18]         --\n",
       "│    └─st_gcn: 2-7                            [32, 128, 40, 18]         [32, 128, 40, 18]         --\n",
       "│    │    └─ConvTemporalGraphical: 3-20       [32, 128, 40, 18]         [32, 128, 40, 18]         16,512\n",
       "│    │    └─Sequential: 3-21                  [32, 128, 40, 18]         [32, 128, 40, 18]         148,096\n",
       "│    │    └─ReLU: 3-22                        [32, 128, 40, 18]         [32, 128, 40, 18]         --\n",
       "│    └─st_gcn: 2-8                            [32, 128, 40, 18]         [32, 256, 20, 18]         --\n",
       "│    │    └─Sequential: 3-23                  [32, 128, 40, 18]         [32, 256, 20, 18]         33,536\n",
       "│    │    └─ConvTemporalGraphical: 3-24       [32, 128, 40, 18]         [32, 256, 40, 18]         33,024\n",
       "│    │    └─Sequential: 3-25                  [32, 256, 40, 18]         [32, 256, 20, 18]         591,104\n",
       "│    │    └─ReLU: 3-26                        [32, 256, 20, 18]         [32, 256, 20, 18]         --\n",
       "│    └─st_gcn: 2-9                            [32, 256, 20, 18]         [32, 256, 20, 18]         --\n",
       "│    │    └─ConvTemporalGraphical: 3-27       [32, 256, 20, 18]         [32, 256, 20, 18]         65,792\n",
       "│    │    └─Sequential: 3-28                  [32, 256, 20, 18]         [32, 256, 20, 18]         591,104\n",
       "│    │    └─ReLU: 3-29                        [32, 256, 20, 18]         [32, 256, 20, 18]         --\n",
       "│    └─st_gcn: 2-10                           [32, 256, 20, 18]         [32, 256, 20, 18]         --\n",
       "│    │    └─ConvTemporalGraphical: 3-30       [32, 256, 20, 18]         [32, 256, 20, 18]         65,792\n",
       "│    │    └─Sequential: 3-31                  [32, 256, 20, 18]         [32, 256, 20, 18]         591,104\n",
       "│    │    └─ReLU: 3-32                        [32, 256, 20, 18]         [32, 256, 20, 18]         --\n",
       "├─Conv2d: 1-3                                 [32, 256, 1, 1]           [32, 20, 1, 1]            5,140\n",
       "========================================================================================================================\n",
       "Total params: 2,632,384\n",
       "Trainable params: 2,632,384\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 41.98\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.55\n",
       "Forward/backward pass size (MB): 1133.57\n",
       "Params size (MB): 10.53\n",
       "Estimated Total Size (MB): 1144.66\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in_channels (int): Number of channels in the input data\n",
    "#     num_class (int): Number of classes for the classification task\n",
    "#     graph_args (dict): The arguments for building the graph\n",
    "#     edge_importance_weighting (bool): If ``True``, adds a learnable\n",
    "#         importance weighting to the edges of the graph\n",
    "#     **kwargs (optional): Other parameters for graph convolution units\n",
    "a = Model(3, 20, graph_args = {\"layout\": \"openpose\"}, edge_importance_weighting=False)\n",
    "summary(a, input_size=(32, 3, 80, 18, 1), col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
