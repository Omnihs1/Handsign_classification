{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from utils.tgcn import ConvTemporalGraphical\n",
    "from utils.graph import Graph\n",
    "from torchinfo import summary\n",
    "\n",
    "class Model(nn.Module):\n",
    "    r\"\"\"Spatial temporal graph convolutional networks.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input data\n",
    "        num_class (int): Number of classes for the classification task\n",
    "        graph_args (dict): The arguments for building the graph\n",
    "        edge_importance_weighting (bool): If ``True``, adds a learnable\n",
    "            importance weighting to the edges of the graph\n",
    "        **kwargs (optional): Other parameters for graph convolution units\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in}, M_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "            :math:`M_{in}` is the number of instance in a frame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, num_class, graph_args,\n",
    "                 edge_importance_weighting, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # load graph\n",
    "        self.graph = Graph(**graph_args)\n",
    "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # build networks\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(self.A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        # fcn for prediction\n",
    "        self.fcn = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.size()\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        x = x.view(N * M, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = x.view(N * M, C, T, V)\n",
    "\n",
    "        # forwad\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        # global pooling\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = x.view(N, M, -1, 1, 1).mean(dim=1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extract_feature(self, x):\n",
    "\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.size()\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        x = x.view(N * M, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = x.view(N * M, C, T, V)\n",
    "\n",
    "        # forwad\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        _, c, t, v = x.size()\n",
    "        feature = x.view(N, M, c, t, v).permute(0, 2, 3, 4, 1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        output = x.view(N, M, -1, t, v).permute(0, 2, 3, 4, 1)\n",
    "\n",
    "        return output, feature\n",
    "\n",
    "class st_gcn(nn.Module):\n",
    "    r\"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input sequence data\n",
    "        out_channels (int): Number of channels produced by the convolution\n",
    "        kernel_size (tuple): Size of the temporal convolving kernel and graph convolving kernel\n",
    "        stride (int, optional): Stride of the temporal convolution. Default: 1\n",
    "        dropout (int, optional): Dropout rate of the final output. Default: 0\n",
    "        residual (bool, optional): If ``True``, applies a residual mechanism. Default: ``True``\n",
    "\n",
    "    Shape:\n",
    "        - Input[0]: Input graph sequence in :math:`(N, in_channels, T_{in}, V)` format\n",
    "        - Input[1]: Input graph adjacency matrix in :math:`(K, V, V)` format\n",
    "        - Output[0]: Outpu graph sequence in :math:`(N, out_channels, T_{out}, V)` format\n",
    "        - Output[1]: Graph adjacency matrix for output data in :math:`(K, V, V)` format\n",
    "\n",
    "        where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "            :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "            :math:`V` is the number of graph nodes.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 dropout=0,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "\n",
    "        self.gcn = ConvTemporalGraphical(in_channels, out_channels,\n",
    "                                         kernel_size[1])\n",
    "\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                (kernel_size[0], 1),\n",
    "                (stride, 1),\n",
    "                padding,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Dropout(dropout, inplace=True),\n",
    "        )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=1,\n",
    "                    stride=(stride, 1)),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "\n",
    "        res = self.residual(x)\n",
    "        x, A = self.gcn(x, A)\n",
    "        x = self.tcn(x) + res\n",
    "\n",
    "        return self.relu(x), A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
       "========================================================================================================================\n",
       "Model                                         [1, 8, 80, 18, 1]         [1, 20]                   --\n",
       "├─BatchNorm1d: 1-1                            [1, 144, 80]              [1, 144, 80]              288\n",
       "├─ModuleList: 1-2                             --                        --                        --\n",
       "│    └─st_gcn: 2-1                            [1, 8, 80, 18]            [1, 64, 80, 18]           --\n",
       "│    │    └─ConvTemporalGraphical: 3-1        [1, 8, 80, 18]            [1, 64, 80, 18]           576\n",
       "│    │    └─Sequential: 3-2                   [1, 64, 80, 18]           [1, 64, 80, 18]           37,184\n",
       "│    │    └─ReLU: 3-3                         [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    └─st_gcn: 2-2                            [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    │    └─ConvTemporalGraphical: 3-4        [1, 64, 80, 18]           [1, 64, 80, 18]           4,160\n",
       "│    │    └─Sequential: 3-5                   [1, 64, 80, 18]           [1, 64, 80, 18]           37,184\n",
       "│    │    └─ReLU: 3-6                         [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    └─st_gcn: 2-3                            [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    │    └─ConvTemporalGraphical: 3-7        [1, 64, 80, 18]           [1, 64, 80, 18]           4,160\n",
       "│    │    └─Sequential: 3-8                   [1, 64, 80, 18]           [1, 64, 80, 18]           37,184\n",
       "│    │    └─ReLU: 3-9                         [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    └─st_gcn: 2-4                            [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    │    └─ConvTemporalGraphical: 3-10       [1, 64, 80, 18]           [1, 64, 80, 18]           4,160\n",
       "│    │    └─Sequential: 3-11                  [1, 64, 80, 18]           [1, 64, 80, 18]           37,184\n",
       "│    │    └─ReLU: 3-12                        [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    └─st_gcn: 2-5                            [1, 64, 80, 18]           [1, 128, 40, 18]          --\n",
       "│    │    └─Sequential: 3-13                  [1, 64, 80, 18]           [1, 128, 40, 18]          8,576\n",
       "│    │    └─ConvTemporalGraphical: 3-14       [1, 64, 80, 18]           [1, 128, 80, 18]          8,320\n",
       "│    │    └─Sequential: 3-15                  [1, 128, 80, 18]          [1, 128, 40, 18]          148,096\n",
       "│    │    └─ReLU: 3-16                        [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    └─st_gcn: 2-6                            [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-17       [1, 128, 40, 18]          [1, 128, 40, 18]          16,512\n",
       "│    │    └─Sequential: 3-18                  [1, 128, 40, 18]          [1, 128, 40, 18]          148,096\n",
       "│    │    └─ReLU: 3-19                        [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    └─st_gcn: 2-7                            [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-20       [1, 128, 40, 18]          [1, 128, 40, 18]          16,512\n",
       "│    │    └─Sequential: 3-21                  [1, 128, 40, 18]          [1, 128, 40, 18]          148,096\n",
       "│    │    └─ReLU: 3-22                        [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    └─st_gcn: 2-8                            [1, 128, 40, 18]          [1, 256, 20, 18]          --\n",
       "│    │    └─Sequential: 3-23                  [1, 128, 40, 18]          [1, 256, 20, 18]          33,536\n",
       "│    │    └─ConvTemporalGraphical: 3-24       [1, 128, 40, 18]          [1, 256, 40, 18]          33,024\n",
       "│    │    └─Sequential: 3-25                  [1, 256, 40, 18]          [1, 256, 20, 18]          591,104\n",
       "│    │    └─ReLU: 3-26                        [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "│    └─st_gcn: 2-9                            [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-27       [1, 256, 20, 18]          [1, 256, 20, 18]          65,792\n",
       "│    │    └─Sequential: 3-28                  [1, 256, 20, 18]          [1, 256, 20, 18]          591,104\n",
       "│    │    └─ReLU: 3-29                        [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "│    └─st_gcn: 2-10                           [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-30       [1, 256, 20, 18]          [1, 256, 20, 18]          65,792\n",
       "│    │    └─Sequential: 3-31                  [1, 256, 20, 18]          [1, 256, 20, 18]          591,104\n",
       "│    │    └─ReLU: 3-32                        [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "├─Conv2d: 1-3                                 [1, 256, 1, 1]            [1, 20, 1, 1]             5,140\n",
       "========================================================================================================================\n",
       "Total params: 2,632,884\n",
       "Trainable params: 2,632,884\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.31\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 35.48\n",
       "Params size (MB): 10.53\n",
       "Estimated Total Size (MB): 46.06\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in_channels (int): Number of channels in the input data\n",
    "#     num_class (int): Number of classes for the classification task\n",
    "#     graph_args (dict): The arguments for building the graph\n",
    "#     edge_importance_weighting (bool): If ``True``, adds a learnable\n",
    "#         importance weighting to the edges of the graph\n",
    "#     **kwargs (optional): Other parameters for graph convolution units\n",
    "a = Model(8, 20, graph_args = {\"layout\": \"openpose\"}, edge_importance_weighting=False)\n",
    "summary(a, input_size=(1, 8, 80, 18, 1), col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, in_features : int, out_features : int,\n",
    "                 n_heads : int, is_concat : bool = True, \n",
    "                 dropout : float = 0.6, \n",
    "                 leaky_relu_negative_slope : float = 0.2):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.is_concat = is_concat\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        if is_concat:\n",
    "            assert out_features % n_heads == 0\n",
    "            self.n_hidden = out_features // n_heads\n",
    "        else:\n",
    "            self.n_hidden = out_features\n",
    "\n",
    "        self.linear = nn.Linear(in_features, self.n_hidden * n_heads, bias = False)\n",
    "        self.attn = nn.Linear(self.n_hidden * 2, 1, bias = False)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=leaky_relu_negative_slope)\n",
    "        self.softmax = nn.Softmax(dim = 3)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, h:torch.Tensor, adj_mat: torch.Tensor):\n",
    "        # h shape (n_nodes, in_features)\n",
    "        # adj_mat shape (n_nodes, n_nodes, n_heads)\n",
    "        # h moi (batch_size, time, n_nodes, in_features)\n",
    "        # adj_mat (n_nodes, n_nodes, n_heads)\n",
    "        batch_size, time, n_nodes, in_features = h.shape\n",
    "        n_nodes = h.shape[2]\n",
    "        # (batch_size, time, n_nodes, in_features) -> (batch_size, time, n_nodes, n_heads, n_hidden)\n",
    "        g = self.linear(h).view(batch_size, time, n_nodes, self.n_heads, self.n_hidden)\n",
    "        # print(g.shape)\n",
    "        # (batch_size, time, n_nodes, n_heads, n_hidden) -> (batch_size, time, n_nodes * n_nodes, n_heads, n_hidden)\n",
    "        g_repeat = g.repeat(1, 1, n_nodes, 1, 1)\n",
    "        # print(g_repeat.shape)\n",
    "        # (batch_size, time, n_nodes, n_heads, n_hidden) -> (batch_size, time, n_nodes * n_nodes, n_heads, n_hidden)\n",
    "        g_repeat_interleave = g.repeat_interleave(n_nodes, dim = 2)\n",
    "        # print(g_repeat_interleave.shape)\n",
    "        # (batch_size, time, n_nodes, n_heads, n_hidden) -> (batch_size, time, n_nodes * n_nodes, n_heads, 2 * n_hidden)\n",
    "        g_concat = torch.cat([g_repeat_interleave, g_repeat], dim = -1)\n",
    "        # (batch_size, time, n_nodes * n_nodes, n_heads, 2 * n_hidden) -> (batch_size, time, n_nodes, n_nodes, n_heads, 2 * n_hidden)\n",
    "        g_concat = g_concat.view(batch_size, time, n_nodes, n_nodes, self.n_heads, 2*self.n_hidden)\n",
    "        \n",
    "        # (batch_size, time, n_nodes, n_nodes, n_heads, 2 * n_hidden) -> (batch_size, time, n_nodes, n_nodes, n_heads, 1) \n",
    "        e = self.attn(g_concat)\n",
    "        # (batch_size, time, n_nodes, n_nodes, n_heads, 1) -> (batch_size, time, n_nodes, n_nodes, n_heads, 1) \n",
    "        e = self.activation(e)\n",
    "        # (batch_size, time, n_nodes, n_nodes, n_heads, 1) -> (batch_size, time, n_nodes, n_nodes, n_heads) \n",
    "        e = e.squeeze(-1)\n",
    "        assert adj_mat.shape[0] == 1 or adj_mat.shape[0] == n_nodes\n",
    "        assert adj_mat.shape[1] == 1 or adj_mat.shape[1] == n_nodes\n",
    "        assert adj_mat.shape[2] == 1 or adj_mat.shape[2] == self.n_heads\n",
    "        \n",
    "        adj_mat = adj_mat.unsqueeze(0).unsqueeze(0)\n",
    "        e = e.masked_fill(adj_mat == 0, float('-inf'))\n",
    "        # (batch_size, time, n_nodes, n_nodes, n_heads) -> (batch_size, time, n_nodes, n_nodes, n_heads)\n",
    "        a = self.softmax(e)\n",
    "        # (batch_size, time, n_nodes, n_nodes, n_heads) -> (batch_size, time, n_nodes, n_nodes, n_heads)\n",
    "        # ??? \n",
    "        a = self.dropout(a)\n",
    "\n",
    "        # (batch_size, time, n_nodes, n_heads, n_hidden) * (batch_size, time, n_nodes, n_nodes, n_heads)\n",
    "        # -> (batch_size, time, n_nodes, n_hidden, n_heads)\n",
    "        attn_res = torch.einsum('abijh, abjhf->abihf', a, g)\n",
    "        \n",
    "        if self.is_concat:\n",
    "            return attn_res.reshape(batch_size, time, n_nodes, self.n_heads * self.n_hidden)\n",
    "        else:\n",
    "            return attn_res.mean(dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 625, 2, 3])\n",
      "torch.Size([1, 80, 625, 2, 3])\n",
      "torch.Size([1, 80, 625, 2, 6])\n",
      "torch.Size([1, 80, 25, 25, 2, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 25, 25, 2, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape tensor goc (N, C, T, V, M)\n",
    "# (batch_size, time, n_nodes, n_heads, n_hidden)\n",
    "x = torch.randn((1, 80, 25, 2, 3))\n",
    "g_repeat = x.repeat(1, 1, 25, 1, 1)\n",
    "print(g_repeat.shape)\n",
    "g_repeat_interleave = x.repeat_interleave(25, dim = 2)\n",
    "print(g_repeat_interleave.shape)\n",
    "g_concat = torch.cat([g_repeat_interleave, g_repeat], dim = -1)\n",
    "print(g_concat.shape)\n",
    "g_concat = g_concat.view(1, 80, 25, 25, 2, 6)\n",
    "print(g_concat.shape)\n",
    "activation = nn.LeakyReLU(negative_slope=0.1)\n",
    "y = activation(g_concat)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 25, 4, 2])\n",
      "torch.Size([1, 80, 625, 4, 2])\n",
      "torch.Size([1, 80, 625, 4, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "AttentionLayer                           [1, 80, 25, 2]            [1, 80, 25, 8]            --\n",
       "├─Linear: 1-1                            [1, 80, 25, 2]            [1, 80, 25, 8]            16\n",
       "├─Linear: 1-2                            [1, 80, 25, 25, 4, 4]     [1, 80, 25, 25, 4, 1]     4\n",
       "├─LeakyReLU: 1-3                         [1, 80, 25, 25, 4, 1]     [1, 80, 25, 25, 4, 1]     --\n",
       "├─Softmax: 1-4                           [1, 80, 25, 25, 4]        [1, 80, 25, 25, 4]        --\n",
       "├─Dropout: 1-5                           [1, 80, 25, 25, 4]        [1, 80, 25, 25, 4]        --\n",
       "===================================================================================================================\n",
       "Total params: 20\n",
       "Trainable params: 20\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.03\n",
       "Forward/backward pass size (MB): 1.73\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 1.75\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "n_heads = 4\n",
    "layer = AttentionLayer(in_features = 2, out_features = 8, n_heads = n_heads, is_concat = True)\n",
    "# h moi (batch_size, time, n_nodes, in_features)\n",
    "summary(layer, input_size = [(1, 80, 25, 2), (25, 25, n_heads)], col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 25, 4, 2])\n",
      "torch.Size([1, 80, 625, 4, 2])\n",
      "torch.Size([1, 80, 625, 4, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_36852\\3367646769.py:50: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert adj_mat.shape[0] == 1 or adj_mat.shape[0] == n_nodes\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_36852\\3367646769.py:51: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert adj_mat.shape[1] == 1 or adj_mat.shape[1] == n_nodes\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_36852\\3367646769.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert adj_mat.shape[2] == 1 or adj_mat.shape[2] == self.n_heads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "layer = AttentionLayer(in_features = 2, out_features = 8, n_heads = n_heads, is_concat = True)\n",
    "torch_input1 = torch.randn(1, 80, 25, 2)\n",
    "torch_input2 = torch.randn(25, 25, n_heads)\n",
    "torch.onnx.export(layer, (torch_input1, torch_input2), \"attentionLayer.onnx\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    r\"\"\"Spatial temporal graph convolutional networks.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of channels in the input data\n",
    "        num_class (int): Number of classes for the classification task\n",
    "        graph_args (dict): The arguments for building the graph\n",
    "        edge_importance_weighting (bool): If ``True``, adds a learnable\n",
    "            importance weighting to the edges of the graph\n",
    "        **kwargs (optional): Other parameters for graph convolution units\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in}, M_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "            :math:`M_{in}` is the number of instance in a frame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, num_class, graph_args,\n",
    "                 edge_importance_weighting, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # load graph\n",
    "        self.graph = Graph(**graph_args)\n",
    "        A = torch.tensor(self.graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # build networks\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "        self.n_heads = 4\n",
    "        self.attention_layer = AttentionLayer(in_channels, in_channels * 4, 4, is_concat=True)\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels*4, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(self.A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        # fcn for prediction\n",
    "        self.fcn = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.size()\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        x = x.view(N * M, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        #           0, 1, 2, 3, 4\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 4, 2, 3).contiguous()\n",
    "        x = x.view(N * M, T, V, C)\n",
    "\n",
    "        print(x.shape)\n",
    "        print(self.A.shape)\n",
    "        adj_mat = self.A.detach().squeeze(dim = 0)\n",
    "        print(adj_mat.shape)\n",
    "        adj_mat = adj_mat.unsqueeze(dim = 2).repeat(1, 1, self.n_heads)\n",
    "        print(adj_mat.shape)\n",
    "        x = self.attention_layer(x, adj_mat)\n",
    "        print(x.shape)\n",
    "        # 0, 1, 2, 3, 4\n",
    "        # [1, 80, 18, 8]\n",
    "        print(f\"N{N}, M{M}, T{T}, V{V}, C{C}\")\n",
    "        # Note C*4\n",
    "        x = x.view(N, M, T, V, C*4)\n",
    "        x = x.permute(0, 1, 4, 2, 3).contiguous()\n",
    "        x = x.view(N * M, C*4, T, V)\n",
    "        print(x.shape)\n",
    "        # forwad\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        # global pooling\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = x.view(N, M, -1, 1, 1).mean(dim=1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def extract_feature(self, x):\n",
    "\n",
    "        # data normalization\n",
    "        N, C, T, V, M = x.size()\n",
    "        x = x.permute(0, 4, 3, 1, 2).contiguous()\n",
    "        x = x.view(N * M, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, M, V, C, T)\n",
    "        x = x.permute(0, 1, 3, 4, 2).contiguous()\n",
    "        x = x.view(N * M, C, T, V)\n",
    "\n",
    "        # forwad\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x, _ = gcn(x, self.A * importance)\n",
    "\n",
    "        _, c, t, v = x.size()\n",
    "        feature = x.view(N, M, c, t, v).permute(0, 2, 3, 4, 1)\n",
    "\n",
    "        # prediction\n",
    "        x = self.fcn(x)\n",
    "        output = x.view(N, M, -1, t, v).permute(0, 2, 3, 4, 1)\n",
    "\n",
    "        return output, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 18, 2])\n",
      "torch.Size([1, 18, 18])\n",
      "torch.Size([18, 18])\n",
      "torch.Size([18, 18, 4])\n",
      "torch.Size([1, 80, 18, 8])\n",
      "N1, M1, T80, V18, C2\n",
      "torch.Size([1, 8, 80, 18])\n",
      "torch.Size([1, 80, 18, 2])\n",
      "torch.Size([1, 18, 18])\n",
      "torch.Size([18, 18])\n",
      "torch.Size([18, 18, 4])\n",
      "torch.Size([1, 80, 18, 8])\n",
      "N1, M1, T80, V18, C2\n",
      "torch.Size([1, 8, 80, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
       "========================================================================================================================\n",
       "Model                                         [1, 2, 80, 18, 1]         [1, 20]                   --\n",
       "├─BatchNorm1d: 1-1                            [1, 36, 80]               [1, 36, 80]               72\n",
       "├─AttentionLayer: 1-2                         [1, 80, 18, 2]            [1, 80, 18, 8]            --\n",
       "│    └─Linear: 2-1                            [1, 80, 18, 2]            [1, 80, 18, 8]            16\n",
       "│    └─Linear: 2-2                            [1, 80, 18, 18, 4, 4]     [1, 80, 18, 18, 4, 1]     4\n",
       "│    └─LeakyReLU: 2-3                         [1, 80, 18, 18, 4, 1]     [1, 80, 18, 18, 4, 1]     --\n",
       "│    └─Softmax: 2-4                           [1, 80, 18, 18, 4]        [1, 80, 18, 18, 4]        --\n",
       "│    └─Dropout: 2-5                           [1, 80, 18, 18, 4]        [1, 80, 18, 18, 4]        --\n",
       "├─ModuleList: 1-3                             --                        --                        --\n",
       "│    └─st_gcn: 2-6                            [1, 8, 80, 18]            [1, 64, 80, 18]           --\n",
       "│    │    └─ConvTemporalGraphical: 3-1        [1, 8, 80, 18]            [1, 64, 80, 18]           576\n",
       "│    │    └─Sequential: 3-2                   [1, 64, 80, 18]           [1, 64, 80, 18]           37,184\n",
       "│    │    └─ReLU: 3-3                         [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    └─st_gcn: 2-7                            [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    │    └─ConvTemporalGraphical: 3-4        [1, 64, 80, 18]           [1, 64, 80, 18]           4,160\n",
       "│    │    └─Sequential: 3-5                   [1, 64, 80, 18]           [1, 64, 80, 18]           37,184\n",
       "│    │    └─ReLU: 3-6                         [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    └─st_gcn: 2-8                            [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    │    └─ConvTemporalGraphical: 3-7        [1, 64, 80, 18]           [1, 64, 80, 18]           4,160\n",
       "│    │    └─Sequential: 3-8                   [1, 64, 80, 18]           [1, 64, 80, 18]           37,184\n",
       "│    │    └─ReLU: 3-9                         [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    └─st_gcn: 2-9                            [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    │    └─ConvTemporalGraphical: 3-10       [1, 64, 80, 18]           [1, 64, 80, 18]           4,160\n",
       "│    │    └─Sequential: 3-11                  [1, 64, 80, 18]           [1, 64, 80, 18]           37,184\n",
       "│    │    └─ReLU: 3-12                        [1, 64, 80, 18]           [1, 64, 80, 18]           --\n",
       "│    └─st_gcn: 2-10                           [1, 64, 80, 18]           [1, 128, 40, 18]          --\n",
       "│    │    └─Sequential: 3-13                  [1, 64, 80, 18]           [1, 128, 40, 18]          8,576\n",
       "│    │    └─ConvTemporalGraphical: 3-14       [1, 64, 80, 18]           [1, 128, 80, 18]          8,320\n",
       "│    │    └─Sequential: 3-15                  [1, 128, 80, 18]          [1, 128, 40, 18]          148,096\n",
       "│    │    └─ReLU: 3-16                        [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    └─st_gcn: 2-11                           [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-17       [1, 128, 40, 18]          [1, 128, 40, 18]          16,512\n",
       "│    │    └─Sequential: 3-18                  [1, 128, 40, 18]          [1, 128, 40, 18]          148,096\n",
       "│    │    └─ReLU: 3-19                        [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    └─st_gcn: 2-12                           [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-20       [1, 128, 40, 18]          [1, 128, 40, 18]          16,512\n",
       "│    │    └─Sequential: 3-21                  [1, 128, 40, 18]          [1, 128, 40, 18]          148,096\n",
       "│    │    └─ReLU: 3-22                        [1, 128, 40, 18]          [1, 128, 40, 18]          --\n",
       "│    └─st_gcn: 2-13                           [1, 128, 40, 18]          [1, 256, 20, 18]          --\n",
       "│    │    └─Sequential: 3-23                  [1, 128, 40, 18]          [1, 256, 20, 18]          33,536\n",
       "│    │    └─ConvTemporalGraphical: 3-24       [1, 128, 40, 18]          [1, 256, 40, 18]          33,024\n",
       "│    │    └─Sequential: 3-25                  [1, 256, 40, 18]          [1, 256, 20, 18]          591,104\n",
       "│    │    └─ReLU: 3-26                        [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "│    └─st_gcn: 2-14                           [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-27       [1, 256, 20, 18]          [1, 256, 20, 18]          65,792\n",
       "│    │    └─Sequential: 3-28                  [1, 256, 20, 18]          [1, 256, 20, 18]          591,104\n",
       "│    │    └─ReLU: 3-29                        [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "│    └─st_gcn: 2-15                           [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "│    │    └─ConvTemporalGraphical: 3-30       [1, 256, 20, 18]          [1, 256, 20, 18]          65,792\n",
       "│    │    └─Sequential: 3-31                  [1, 256, 20, 18]          [1, 256, 20, 18]          591,104\n",
       "│    │    └─ReLU: 3-32                        [1, 256, 20, 18]          [1, 256, 20, 18]          --\n",
       "├─Conv2d: 1-4                                 [1, 256, 1, 1]            [1, 20, 1, 1]             5,140\n",
       "========================================================================================================================\n",
       "Total params: 2,632,688\n",
       "Trainable params: 2,632,688\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 1.31\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 36.33\n",
       "Params size (MB): 10.53\n",
       "Estimated Total Size (MB): 46.88\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in_channels (int): Number of channels in the input data\n",
    "#     num_class (int): Number of classes for the classification task\n",
    "#     graph_args (dict): The arguments for building the graph\n",
    "#     edge_importance_weighting (bool): If ``True``, adds a learnable\n",
    "#         importance weighting to the edges of the graph\n",
    "#     **kwargs (optional): Other parameters for graph convolution units\n",
    "a = Model(2, 20, graph_args = {\"layout\": \"openpose\"}, edge_importance_weighting=False)\n",
    "x = torch.randn(1, 2, 80, 18, 1)\n",
    "y = a(x)\n",
    "summary(a, input_size=(1, 2, 80, 18, 1), col_names=[\"input_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 80, 18, 8)\n",
    "y = x.view(1, 1, 80, 18, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
